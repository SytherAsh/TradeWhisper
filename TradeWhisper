{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10045925,"sourceType":"datasetVersion","datasetId":6188989}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-29T15:03:09.364017Z","iopub.execute_input":"2024-11-29T15:03:09.365018Z","iopub.status.idle":"2024-11-29T15:03:09.790468Z","shell.execute_reply.started":"2024-11-29T15:03:09.364961Z","shell.execute_reply":"2024-11-29T15:03:09.789023Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install yfinance pandas\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T13:34:39.617879Z","iopub.execute_input":"2024-11-30T13:34:39.618260Z","iopub.status.idle":"2024-11-30T13:35:16.966779Z","shell.execute_reply.started":"2024-11-30T13:34:39.618230Z","shell.execute_reply":"2024-11-30T13:35:16.965355Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Delete\n--","metadata":{}},{"cell_type":"code","source":"# !rm -rf /kaggle/working/*","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-29T15:03:56.832170Z","iopub.execute_input":"2024-11-29T15:03:56.833122Z","iopub.status.idle":"2024-11-29T15:03:56.837232Z","shell.execute_reply.started":"2024-11-29T15:03:56.833070Z","shell.execute_reply":"2024-11-29T15:03:56.836165Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Alpha_Vantage\n--","metadata":{}},{"cell_type":"code","source":"# import requests\n# import csv\n\n# API_KEY = \"BE5JMSE1238LY1ZC\"\n# base_url = \"https://www.alphavantage.co/query\"\n\n# # Example: Replace with tickers list from a stock screener or exchange API\n# tickers = [\"RELIANCE.BSE\", \"TCS.BSE\", \"INFY.BSE\"]\n\n# for ticker in tickers:\n#     url = f\"{base_url}?function=TIME_SERIES_DAILY&symbol={ticker}&apikey={API_KEY}&datatype=csv\"\n#     response = requests.get(url)\n    \n#     if response.status_code == 200:\n#         filename = f\"{ticker}.csv\"\n#         with open(filename, \"wb\") as file:\n#             file.write(response.content)\n#         print(f\"Data for {ticker} saved to {filename}\")\n#     else:\n#         print(f\"Failed to fetch data for {ticker}: {response.status_code}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-29T15:03:56.852278Z","iopub.execute_input":"2024-11-29T15:03:56.852707Z","iopub.status.idle":"2024-11-29T15:03:56.862089Z","shell.execute_reply.started":"2024-11-29T15:03:56.852662Z","shell.execute_reply":"2024-11-29T15:03:56.860906Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"NIFTY FIFTY Companies\n--","metadata":{}},{"cell_type":"code","source":"\nnifty_tickers = {\n    \"Adani Enterprises\": \"ADANIENT.NS\",\n    \"Adani Ports and SEZ\": \"ADANIPORTS.NS\",\n    \"Asian Paints\": \"ASIANPAINT.NS\",\n    \"Axis Bank\": \"AXISBANK.NS\",\n    \"Bajaj Auto\": \"BAJAJ-AUTO.NS\",\n    \"Bajaj Finance\": \"BAJFINANCE.NS\",\n    \"Bajaj Finserv\": \"BAJAJFINSV.NS\",\n    \"Bharti Airtel\": \"BHARTIARTL.NS\",\n    \"BPCL\": \"BPCL.NS\",\n    \"Britannia Industries\": \"BRITANNIA.NS\",\n    \"Cipla\": \"CIPLA.NS\",\n    \"Coal India\": \"COALINDIA.NS\",\n    \"Divi's Laboratories\": \"DIVISLAB.NS\",\n    \"Dr. Reddy's Laboratories\": \"DRREDDY.NS\",\n    \"Eicher Motors\": \"EICHERMOT.NS\",\n    \"Grasim Industries\": \"GRASIM.NS\",\n    \"HCL Technologies\": \"HCLTECH.NS\",\n    \"HDFC Bank\": \"HDFCBANK.NS\",\n    \"HDFC Life\": \"HDFCLIFE.NS\",\n    \"Hero MotoCorp\": \"HEROMOTOCO.NS\",\n    \"Hindalco Industries\": \"HINDALCO.NS\",\n    \"Hindustan Unilever\": \"HINDUNILVR.NS\",\n    \"ICICI Bank\": \"ICICIBANK.NS\",\n    \"IndusInd Bank\": \"INDUSINDBK.NS\",\n    \"Infosys\": \"INFY.NS\",\n    \"ITC\": \"ITC.NS\",\n    \"JSW Steel\": \"JSWSTEEL.NS\",\n    \"Kotak Mahindra Bank\": \"KOTAKBANK.NS\",\n    \"Larsen & Toubro\": \"LT.NS\",\n    \"Mahindra & Mahindra\": \"M&M.NS\",\n    \"Maruti Suzuki\": \"MARUTI.NS\",\n    \"Nestle India\": \"NESTLEIND.NS\",\n    \"NTPC\": \"NTPC.NS\",\n    \"Oil and Natural Gas Corporation (ONGC)\": \"ONGC.NS\",\n    \"Power Grid Corporation\": \"POWERGRID.NS\",\n    \"Reliance Industries\": \"RELIANCE.NS\",\n    \"State Bank of India\": \"SBIN.NS\",\n    \"Sun Pharma\": \"SUNPHARMA.NS\",\n    \"Tata Consumer Products\": \"TATACONSUM.NS\",\n    \"Tata Consultancy Services\": \"TCS.NS\",\n    \"Tata Motors\": \"TATAMOTORS.NS\",\n    \"Tata Steel\": \"TATASTEEL.NS\",\n    \"Tech Mahindra\": \"TECHM.NS\",\n    \"Titan Company\": \"TITAN.NS\",\n    \"UltraTech Cement\": \"ULTRACEMCO.NS\",\n    \"UPL\": \"UPL.NS\",\n    \"Wipro\": \"WIPRO.NS\",\n    \"Zee Entertainment Enterprises\": \"ZEEL.NS\"\n}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-29T15:03:56.863714Z","iopub.execute_input":"2024-11-29T15:03:56.864819Z","iopub.status.idle":"2024-11-29T15:03:56.880171Z","shell.execute_reply.started":"2024-11-29T15:03:56.864769Z","shell.execute_reply":"2024-11-29T15:03:56.879060Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"STORE/FETCH\n--","metadata":{}},{"cell_type":"code","source":"import yfinance as yf\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os  # Importing os module to interact with the file system\n\n# Function to fetch data for individual companies\ndef fetch_company_data(ticker, start_date=\"2023-10-01\", end_date=\"2023-11-30\"):\n    \"\"\"\n    Fetch stock data for a single company.\n    Args:\n        ticker (str): Stock ticker symbol.\n        start_date (str): Start date for fetching data.\n        end_date (str): End date for fetching data.\n    Returns:\n        DataFrame: Company stock data.\n    \"\"\"\n    data = yf.download(ticker, start=start_date, end=end_date)\n    return data\n\n# Create a folder to save the CSV files\nfolder_name = 'Stocks_data'\nif not os.path.exists(folder_name):\n    os.makedirs(folder_name)  # Create folder if it doesn't exist\n\n# Fetching and saving data for all Nifty 50 companies\nfor company, ticker in nifty_tickers.items():\n    print(f\"Fetching data for {company} ({ticker})\")\n    company_data = fetch_company_data(ticker)\n    # Save data to CSV file inside the folder\n    company_data.to_csv(os.path.join(folder_name, f\"{ticker}_data.csv\"))\n\nprint(\"Downloading Completed\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-29T15:03:56.881692Z","iopub.execute_input":"2024-11-29T15:03:56.882124Z","iopub.status.idle":"2024-11-29T15:04:04.658496Z","shell.execute_reply.started":"2024-11-29T15:03:56.882078Z","shell.execute_reply":"2024-11-29T15:04:04.657450Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_company_data(ticker, start_date=\"2024-10-01\", end_date=\"2024-11-29\"):\n    \"\"\"\n    Plot stock data for a specific company.\n    Args:\n        ticker (str): Stock ticker symbol.\n    \"\"\"\n    data = fetch_company_data(ticker, start_date, end_date)\n    plt.figure(figsize=(12, 6))\n    plt.plot(data.index, data['Close'], label=ticker)\n    plt.title(f\"{ticker} Stock Performance\")\n    plt.xlabel(\"Date\")\n    plt.ylabel(\"Close Price\")\n    plt.legend()\n    plt.grid()\n    plt.show()\n\n# Example: Plotting data for \"Adani Enterprises\"\nplot_company_data(\"ADANIENT.NS\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-29T15:04:23.875327Z","iopub.execute_input":"2024-11-29T15:04:23.875741Z","iopub.status.idle":"2024-11-29T15:04:24.351696Z","shell.execute_reply.started":"2024-11-29T15:04:23.875706Z","shell.execute_reply":"2024-11-29T15:04:24.350563Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# df=pd.read_csv(\"/kaggle/working/Stocks_data/ADANIENT.NS_data.csv\")\n# # df.columns\n# df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-29T03:57:48.006803Z","iopub.execute_input":"2024-11-29T03:57:48.007183Z","iopub.status.idle":"2024-11-29T03:57:48.011999Z","shell.execute_reply.started":"2024-11-29T03:57:48.007151Z","shell.execute_reply":"2024-11-29T03:57:48.010731Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"NIFTY\n--","metadata":{}},{"cell_type":"code","source":"# Importing libraries\nimport yfinance as yf\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Function to fetch Nifty Index data\ndef fetch_nifty_index_data(ticker=\"^NSEI\", start_date=\"2024-01-01\", end_date=\"2024-11-29\"):\n    \"\"\"\n    Fetch stock data for the Nifty 50 index.\n    Args:\n        ticker (str): Stock ticker for Nifty 50 index.\n        start_date (str): Start date for fetching data.\n        end_date (str): End date for fetching data.\n    Returns:\n        DataFrame: Nifty index data.\n    \"\"\"\n    data = yf.download(ticker, start=start_date, end=end_date)\n    return data\n\n# Fetching Nifty 50 index data\nnifty_data = fetch_nifty_index_data()\n\n# Saving Nifty index data to CSV\nnifty_data.to_csv(\"nifty_index_data.csv\")\n\n# Visualization of Nifty 50 Index\ndef plot_nifty_index(data):\n    \"\"\"\n    Plot Nifty 50 index data.\n    Args:\n        data (DataFrame): Nifty 50 index data.\n    \"\"\"\n    plt.figure(figsize=(12, 6))\n    plt.plot(data.index, data['Close'], label=\"Nifty 50 Index\")\n    plt.title(\"Nifty 50 Index Performance\")\n    plt.xlabel(\"Date\")\n    plt.ylabel(\"Close Price\")\n    plt.legend()\n    plt.grid()\n    plt.show()\n\n# Plotting the Nifty Index\nplot_nifty_index(nifty_data)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T13:35:16.969013Z","iopub.execute_input":"2024-11-30T13:35:16.969353Z","iopub.status.idle":"2024-11-30T13:35:18.552249Z","shell.execute_reply.started":"2024-11-30T13:35:16.969316Z","shell.execute_reply":"2024-11-30T13:35:18.551264Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df=pd.read_csv(\"/kaggle/working/nifty_index_data.csv\")\n# df.columns\ndf = df.iloc[2:]\ndf = df.reset_index(drop=True)\ndf.to_csv('nifty_index_data.csv', index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T13:35:33.746116Z","iopub.execute_input":"2024-11-30T13:35:33.746600Z","iopub.status.idle":"2024-11-30T13:35:33.763609Z","shell.execute_reply.started":"2024-11-30T13:35:33.746555Z","shell.execute_reply":"2024-11-30T13:35:33.762080Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T13:35:48.171406Z","iopub.execute_input":"2024-11-30T13:35:48.171814Z","iopub.status.idle":"2024-11-30T13:35:48.192832Z","shell.execute_reply.started":"2024-11-30T13:35:48.171778Z","shell.execute_reply":"2024-11-30T13:35:48.191808Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"REDDIT\n--","metadata":{}},{"cell_type":"code","source":"!pip install praw\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-29T04:58:59.444776Z","iopub.execute_input":"2024-11-29T04:58:59.445922Z","iopub.status.idle":"2024-11-29T04:59:09.888850Z","shell.execute_reply.started":"2024-11-29T04:58:59.445873Z","shell.execute_reply":"2024-11-29T04:59:09.887400Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Financial_Keywords\n--","metadata":{}},{"cell_type":"code","source":"\nkeywords = [\n    # General Finance Keywords\n    \"Finance\", \"Stocks\", \"Stock market\", \"Investing\", \"Investment\",\n    \"Trading\", \"Equity\", \"Market trends\", \"Nifty 50\", \"Sensex\",\n    \"Stock analysis\", \"Share prices\", \"IPO\", \"Bull market\", \"Bear market\",\n    \"Portfolio\", \"Mutual funds\", \"Derivatives\", \"Dividend\",\n    \"Economic growth\", \"Recession\", \"Profit\", \"Loss\", \"Financial news\",\n    \"Quarterly earnings\", \"Revenue\", \"Market capitalization\", \"Valuation\",\n    \"Asset management\", \"Debt\", \"Risk management\", \"Capital\", \"Brokerage\",\n    \"Hedge funds\", \"Financial planning\", \"Wealth management\", \"Cryptocurrency\",\n    \"Forex\",\n    \n    # Nifty Company Names\n    \"Adani Enterprises\", \"Adani Ports and SEZ\", \"Asian Paints\", \"Axis Bank\",\n    \"Bajaj Auto\", \"Bajaj Finance\", \"Bajaj Finserv\", \"Bharti Airtel\", \"BPCL\",\n    \"Britannia Industries\", \"Cipla\", \"Coal India\", \"Divi's Laboratories\",\n    \"Dr. Reddy's Laboratories\", \"Eicher Motors\", \"Grasim Industries\",\n    \"HCL Technologies\", \"HDFC Bank\", \"HDFC Life\", \"Hero MotoCorp\",\n    \"Hindalco Industries\", \"Hindustan Unilever\", \"ICICI Bank\",\n    \"IndusInd Bank\", \"Infosys\", \"ITC\", \"JSW Steel\", \"Kotak Mahindra Bank\",\n    \"Larsen & Toubro\", \"Mahindra & Mahindra\", \"Maruti Suzuki\", \"Nestle India\",\n    \"NTPC\", \"ONGC\", \"Power Grid Corporation\", \"Reliance Industries\",\n    \"State Bank of India\", \"Sun Pharma\", \"Tata Consumer Products\",\n    \"Tata Consultancy Services\", \"Tata Motors\", \"Tata Steel\", \"Tech Mahindra\",\n    \"Titan Company\", \"UltraTech Cement\", \"UPL\", \"Wipro\", \"Zee Entertainment Enterprises\",\n\n    # Nifty Company Tickers\n    \"ADANIENT.NS\", \"ADANIPORTS.NS\", \"ASIANPAINT.NS\", \"AXISBANK.NS\",\n    \"BAJAJ-AUTO.NS\", \"BAJFINANCE.NS\", \"BAJAJFINSV.NS\", \"BHARTIARTL.NS\", \"BPCL.NS\",\n    \"BRITANNIA.NS\", \"CIPLA.NS\", \"COALINDIA.NS\", \"DIVISLAB.NS\", \"DRREDDY.NS\",\n    \"EICHERMOT.NS\", \"GRASIM.NS\", \"HCLTECH.NS\", \"HDFCBANK.NS\", \"HDFCLIFE.NS\",\n    \"HEROMOTOCO.NS\", \"HINDALCO.NS\", \"HINDUNILVR.NS\", \"ICICIBANK.NS\",\n    \"INDUSINDBK.NS\", \"INFY.NS\", \"ITC.NS\", \"JSWSTEEL.NS\", \"KOTAKBANK.NS\",\n    \"LT.NS\", \"M&M.NS\", \"MARUTI.NS\", \"NESTLEIND.NS\", \"NTPC.NS\", \"ONGC.NS\",\n    \"POWERGRID.NS\", \"RELIANCE.NS\", \"SBIN.NS\", \"SUNPHARMA.NS\", \"TATACONSUM.NS\",\n    \"TCS.NS\", \"TATAMOTORS.NS\", \"TATASTEEL.NS\", \"TECHM.NS\", \"TITAN.NS\",\n    \"ULTRACEMCO.NS\", \"UPL.NS\", \"WIPRO.NS\", \"ZEEL.NS\"\n]\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"REDDIT_SCRAP\n--","metadata":{}},{"cell_type":"code","source":"import praw\nimport pandas as pd\n\n# Initialize Reddit API client\nreddit = praw.Reddit(\n    client_id=\"Oo9d1t7aNIqyhID45-u_NA\",\n    client_secret=\"3dwsq_2jfceHdF_Q5cB2XKu9GXbvaQ\",\n    user_agent=\"ScytherAsh\",  # e.g., \"script:my_reddit_scraper:v1.0 (by u/your_username)\"\n)\n\n\n# Fetch data\nresults = []\n\nfor keyword in keywords:\n    subreddit = reddit.subreddit(\"all\")\n    hot_posts = subreddit.search(keyword, sort=\"hot\", limit=100)\n    top_posts = subreddit.search(keyword, sort=\"top\", limit=100)\n\n    for post in hot_posts:\n        results.append({\n            \"Title\": post.title,\n            \"Description\": post.selftext,\n            \"URL\": post.url,\n            \"Score\": post.score,\n            \"Comments Count\": post.num_comments,\n            \"Keyword\": keyword\n        })\n\n    for post in top_posts:\n        results.append({\n            \"Title\": post.title,\n            \"Description\": post.selftext,\n            \"URL\": post.url,\n            \"Score\": post.score,\n            \"Comments Count\": post.num_comments,\n            \"Keyword\": keyword\n        })\n    # print(\"-><-\")\n\n# Filter posts\nfiltered_results = [\n    result for result in results\n    if any(keyword.lower() in (result['Title'] + result['Description']).lower() for keyword in keywords)\n]\n\n# Export to CSV\ndf = pd.DataFrame(filtered_results)\ndf.to_csv(\"reddit_finance_data.csv\", index=False)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import praw\nimport pandas as pd\nimport datetime\n\n# Initialize Reddit API client\nreddit = praw.Reddit(\n    client_id=\"Oo9d1t7aNIqyhID45-u_NA\",\n    client_secret=\"3dwsq_2jfceHdF_Q5cB2XKu9GXbvaQ\",\n    user_agent=\"StockPredictionBot\",\n)\n\n# Expanded list of keywords related to stock market and finance\nkeywords = [\n    'stock market', 'Nifty 50', 'investment', 'economy', 'financial analysis', 'market trends', \n    'portfolio', 'stock prices', 'stocks to buy', 'financial news', 'corporate earnings', \n    'dividends', 'equity markets', 'capital markets', 'market sentiment', 'stock picks', \n    'technical analysis', 'fundamental analysis', 'stock prediction', 'day trading', 'forex market', \n    'cryptocurrency', 'bonds', 'ETFs', 'commodities', 'Reliance Industries', 'Tata Consultancy Services', \n    'HDFC Bank', 'Infosys', 'Bharti Airtel', 'State Bank of India', 'ICICI Bank', 'Wipro', 'Mahindra & Mahindra', \n    'Maruti Suzuki', 'Automobile sector', 'IT sector', 'Pharma stocks', 'Energy stocks', 'Real estate sector', \n    'Banking stocks', 'Consumer goods', 'Green energy', 'Financial services', 'global market', 'global economy', \n    'US market', 'Europe economy', 'China stock market', 'market crashes', 'financial crises', 'inflation rates', \n    'interest rates', 'fiscal policy', 'quantitative easing', 'market correction', 'central bank decisions', \n    'geopolitical risk', 'trade wars', 'global trade', 'market sentiment', 'investor sentiment', 'stock market predictions', \n    'market news', 'financial advice', 'financial predictions', 'stock market crash', 'recession fears', \n    'inflation impact', 'monetary policy', 'stock market rally', 'market volatility', 'earnings reports', \n    'quarterly earnings', 'financial report', 'GDP growth', 'unemployment rate', 'consumer confidence', \n    'retail sales data', 'inflation rate', 'PPI', 'CPI', 'interest rate hike', 'economic outlook', \n    'economic recovery', 'central bank rates'\n]\n\n# List to store filtered posts\nfiltered_results = []\ni=0\n# Fetch data\nfor keyword in keywords:\n    subreddit = reddit.subreddit(\"all\")\n    hot_posts = subreddit.search(keyword, sort=\"hot\", limit=5)\n    top_posts = subreddit.search(keyword, sort=\"top\", limit=5)\n\n    # Iterate over hot_posts\n    for post in hot_posts:\n        # Convert title and selftext to strings before concatenating\n        title = str(post.title)\n        description = str(post.selftext)\n\n        # Check if the description contains the keyword\n        if any(keyword.lower() in (title + description).lower() for keyword in keywords):\n            if description:  # Ensure there is a description\n                # Concatenate all information into a single tag (description)\n                tag = f\"Title: {title} | Description: {description} | Score: {post.score} | Comments: {post.num_comments} | Keyword: {keyword}\"\n                \n                # Extract and format the date\n                post_date = datetime.datetime.utcfromtimestamp(post.created_utc).strftime('%Y-%m-%d %H:%M:%S')\n\n                # Append the tag and date to the filtered results\n                filtered_results.append({\n                    \"Tag\": tag,  # All information in one field\n                    \"Date\": post_date  # Separate date column\n                })\n\n    # Iterate over top_posts\n    for post in top_posts:\n        # Convert title and selftext to strings before concatenating\n        title = str(post.title)\n        description = str(post.selftext)\n\n        # Check if the description contains the keyword\n        if any(keyword.lower() in (title + description).lower() for keyword in keywords):\n            if description:  # Ensure there is a description\n                # Concatenate all information into a single tag (description)\n                tag = f\"Title: {title} | Description: {description} | Score: {post.score} | Comments: {post.num_comments} | Keyword: {keyword}\"\n                \n                # Extract and format the date\n                post_date = datetime.datetime.utcfromtimestamp(post.created_utc).strftime('%Y-%m-%d %H:%M:%S')\n\n                # Append the tag and date to the filtered results\n                filtered_results.append({\n                    \"Tag\": tag,  # All information in one field\n                    \"Date\": post_date  # Separate date column\n                })\n    print(\"-\"*i)\n    i+=1\n# Convert to DataFrame\ndf_filtered = pd.DataFrame(filtered_results)\n\n# Store the filtered data in a CSV file\ndf_filtered.to_csv(\"filtered_reddit_finance_data.csv\", index=False)\n\nprint(f\"Filtered data has been saved to 'filtered_reddit_finance_data.csv'.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"ZIP\n--","metadata":{}},{"cell_type":"code","source":"import shutil\nimport os\n\n# Path to the folder you want to zip\nfolder_name = '/kaggle/working/Stocks_data'\n\n# Create a zip file from the folder\nzip_file_name = '/kaggle/working/Stocks_data.zip'\nshutil.make_archive(zip_file_name.replace('.zip', ''), 'zip', folder_name)\n\nprint(\"Zipping completed!\")\n\n# The file `Stocks_data.zip` will now be available in the output folder.\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-29T15:10:57.492429Z","iopub.execute_input":"2024-11-29T15:10:57.492868Z","iopub.status.idle":"2024-11-29T15:10:57.516913Z","shell.execute_reply.started":"2024-11-29T15:10:57.492831Z","shell.execute_reply":"2024-11-29T15:10:57.515788Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}